A ``primitive oriented'' scripting language core.

Is it possible to write a C application with an ``invisible''
scripting language?  I.e. use a (dynamically typed) language during
prototype development and debugging, but ``optimize it out''
completely in the deployed application?

This project should be understood in a background of embedded control
programming problems.

I've been using the C + scripting approach for a while, and the
conclusion I make is that I spend too much time on the ``impedance
match'' between the C side and the scripting language.  Is it possible
to find a way to write C primitives such that it is easily
(automatically) incorporated in the scripting side?

If the answer is yes (and I think it is), then it is probably best to
build the _whole_ scripting language on such C primitives.

This project is roughly based on the following ideas:

   * C primitives can take the semantics of _lightweight tasks_.
     Along side other benefits of concurrency-oriented programming,
     the property of interest is the ability to decouple the C side
     from the scripting language's _memory_ and _control_ models.

   * Concurrency-oriented programming allows intermediate composite
     data types to be replaced with serial channels and protocols.
     (``Pre-emptive Deforestation'').

   * Linear memory model: C primitives use only atoms which are either
     C primitives (integers and floats), or abstract objects whos
     ownership is clearly indicated.

This would allow to build a library of primitive operations and
datatypes that can be linked with any kind of scripting language
during prototyping or debugging.

The idea is that by isolating the primitives from the memory and
control models of the debugging code, in a final application all
``scripting glue'' can be optimized away and replaced with a minimal
scheduler and memory manager, possibly both static.



Entry: A bit less cryptic
Date: Tue Aug  4 11:14:36 CEST 2009

From a practical day-to-day problem solving pov, C is not going
anywhere because next to a programming language, it is also an
interface standard.  Anything that tries to incorporate modern
language techniques in an embedded programming project needs to play
nice with C.

So, instead of focussing on building new languages, I think it is
worthwhile to do some semantics engineering on subsets of C itself, by
providing an infrastructure that makes it easier to bootstrap
``functional, concurrency oriented C code''.

Hopefully this idea will become easier to articulate once the
implementation is done.

The goal is this:

   * Write a re-usable collection of C primitives necessary to support
     a dynamically typed scripting language, but do this in such a way
     that it does _not_ depend on external memory or control models.

   * To test the primitives and the programming method, write a couple
     of dyntyped scripting languages (memory and control models) on
     top of the primitives.  I'm thinking about two: a PF-like
     concatenative linear stack language and a Scheme-like
     CONS/CONT/GC based language.

   * Write a compiler for static memory allocation and scheduling to
     optimize away the scripting layer.

Later this could be extended with an ML-style statically typed
language.  Given that the goal of the project is _prototyping_ which
is mainly _evolving specification_ I think it's better to stick to a
simpler dynamically typed approach.


Entry: CEKS machine
Date: Tue Aug  4 11:25:38 CEST 2009

Scheme implemented in terms of a CEKS[1] machine.  Focus on the
evaluator first and ignore GC.  Some CEKS machine for
Javascript[3][4].

It might be easier to start with the CEK machine, and add the store
and GC later.

Anyways..  I started with the GC.  Bottom up seems better.  It already
gives a way to encode types.

[1] http://www.cs.utah.edu/plt/publications/pllc.pdf
[2] md5://3ab517a1167f86ef52caf3bf1a4fdb0c
[3] http://wiki.ecmascript.org/doku.php?id=meetings:dave_herman_presentation
[4] http://www.ccs.neu.edu/home/dherman/javascript/
[5] http://www.cs.utah.edu/~mflatt/past-courses/cs6520/public_html/s00/secd.ps

Entry: Lightweight tasks
Date: Tue Aug  4 12:20:48 CEST 2009

Based on the interface present in GNU PTH[1].

[1] http://www.gnu.org/software/pth/



Entry: Primitives and Composition, an OS?
Date: Tue Aug  4 12:25:20 CEST 2009

Any form of language design is based on building primitives (axioms)
and composition mechanism (inference rules).

Is is a stretch to say that an Operating System is actually a
composition mechanism?  If tasks are primitives, gluing tasks together
is what the OS does.


Entry: Aspect oriented programming
Date: Tue Aug  4 12:29:47 CEST 2009

The idea I'm trying to encode is the addition of join points to a C
program: make all these points available to an observer (scripting
language).

[1] http://en.wikipedia.org/wiki/Aspect_oriented_programming


Entry: Garbage Collector
Date: Tue Aug  4 14:53:52 CEST 2009

I've added a simple copying GC in ceks/gc.c for allocating vectors, as
a memory model for implementing the Scheme interpreter.  It uses
tagged objects: vectors, atoms, integers, and one available user tag.

The vectors themselves can be tagged (i.e. to implement a couple of
primitive structs) when the maximum vector size size is limited.

[1] http://www.brpreiss.com/books/opus5/html/page426.html

Entry: Symbols
Date: Tue Aug  4 17:58:47 CEST 2009

Instead of using a hash table, a preliminary implementation could just
use a stack.  This will make parsing slower, but can be easily changed
later.


Entry: Continuations
Date: Tue Aug  4 20:32:34 CEST 2009

So.. ISWIM uses n-ary primitive application, but unary abstraction and
application.  Why is this?  It seems that it makes the extension of
the environment on application easier: only a single variable has to
be added.

Maybe this isn't necessary for Scheme.  A multivalued application adds
all variables at the same time.  Instead of arg,fun,opd as explained
in PLLC, I needs just a single type that evaluates all variables in an
application from left to right, starting with the function position,
and then performs either an application (extending the environment) or
a primitive evaluation (production of a value).

So how to represent (x x x _ x x x) where "_" is the hole?

In short: what does the CEKS machine do?

   It converts the current expression and its continuation in a
   simplified expression and an updated continuation.  It is
   _application_ (triggered by the availability of the last argument)
   that _pops_ the K stack.

So.. Representing continuations.

(((f a b) E) K) -> ( _ (((f E) (a E) (b E)) K))
                -> ((f E) (((a E) (b E)) K))



Entry: Objects and Lambdas
Date: Wed Aug  5 09:43:14 CEST 2009

What I'm trying to accomplish probably has a lot of parallells with
COLA[1].  However, my concern is mostly interoperability with C.

Anyways.  GC and objects.  It might be wise to require objects to
exhibit a class structure: each object points to a record of methods,
where the first couple are used by the GC.
 

[1] http://piumarta.com/software/cola/


Entry: Confused about primitives
Date: Wed Aug  5 13:14:07 CEST 2009

This is ironic: the goal is to properly define primitives, but I'm
already getting hosed!

Once conclusion to draw: there is a set of C primitives that is best
written directly in the required API (sc ,object, ...) -> object
instead of in unwrapped C, because of the tight coupling with the data
representation.  These _direct primitives_ are written manually.

In short: to keep things simple, the interpreter is written in terms
of primitive functions using all scheme datatypes (ala tinyscheme).

What cannot be avoided however is functions that convert between
scheme and C values (esp. strings<-> and ints).  it's best to limit
the use however, and try to use as much as possible real scheme
primitives to avoid duplication (don't give in to premature opti
here!).

So, let's try it:

          All C functions used in the implementation of the Scheme
          interpreter are Scheme primitives.

This fixes the primitive calling convention to:

object fn(sc*, object, ...)

This will raise other problems since I'm not sure it's possible to
have variable argument invokation (assumed from Pure Data source).


Entry: Representing constants
Date: Wed Aug  5 13:54:45 CEST 2009

I might be useful to make it possible to directly cast non-managed
objects, by assuming the class pointer is in the slot _before_ the
pointer.  It is upto the user then to _never_ place them inside GC
managed vectors, as they won't have a valid class pointer.

Elaborate on this a bit..

I.e. it would be nice for a (const char *) to be a valid object that
can reside in a collected data structure.  I.e. the object itself
should be recognizable as not requiring free().

The problem then is that I'm running out of tags:

00 non-managed pointer
01 vector
10 integer
11 bool

Using more than 2 tag bits places extra contstraints on pointer
alignment.  Booleans are useful for predicate implementation in
Scheme.

It is possible however to use the 01 vector slot, since we know what
that will point to:
     - integer (it's a live vector, and the int = size)
     - vector  (moved object)

This could be a non-managed pointer to represent a class?

Maybe another workaround is simpler: doubly wrapping all predicates
and representing bools as integers.

Let's stick to what we have and thing about this a bit more.. It looks
like bools are more useful than constants.  

Otoh: since bools require only two values, and are actually constants,
the problem is solved:


00 constant = non-managed pointer
01 vector
10 integer
11 managed pointer


Let's implement this first before rewriting everything to primitives.


Entry: Unsafe pointers
Date: Wed Aug  5 15:49:26 CEST 2009

I get it now: by making sure the atom_class pointer is the slot one
_before_ the atom pointer, it is possible to write unsafe functions
without too much hassle.

The free() pointer is stored in a class object.  This class object is
the value's type.  Some values however are only statically typed, and
appear as unsafe pointers if they make it into Scheme land.



Entry: debugging
Date: Wed Aug  5 17:48:59 CEST 2009

Hmm.. it's more difficult than I thought.  The interpreter itself I
can probably get debugged, since its structure is quite
straightforward.  However, the GC is going to be an adventure.
Currently I have no way to properly mark roots in case GC is
triggered inside a C primitive.

During the evaluation of step() we could push all allocated atoms to a
stack, and discard it at the end.  This makes sure that intermediate
data will not be freed.

Alternatively, the heap could be marked such that all objects past the
marker need to be copied first.

But this then wouldn't work if there are 2 or more collections.

Alternatively, the marking point could be translated into a vector
that is then added to a local stack of references.

The real question is: does the interpreter know what to mark?

Let's change a gc->root into a callback function.

Done.

Now it shouldn't be to hard to turn a gc marker into an array.
Basicly something like this:

        sc->marker = gc_marker(sc->gc)
        step()
        free_retain_stack()

If there is a collection we do something like

        push_retain_stack(gc_marker_to_vector(sc->marker))
        mark_all()
        sc->marker = gc_marker(sc->gc)


OR

do it manually.
which is probably too error-prone..

Ok.. what about keeping most of it hidden inside the GC.

When the GC calls mark_roots() it will pass in a vector of references
containing the objects that were saved since the last border mark.

Actually, this fancy trick doesn't work because the C stack still has
the _old_ pointers.

Not simple!

One option would be to abort the primitive whenever a collection is
necessary.  If they are written in a purely functional style this
shouldn't be a problem.


Entry: mixing GC and C
Date: Wed Aug  5 19:44:17 CEST 2009

The problem is this: a gc_alloc() inside a primitive might trigger a
collection.  At that point, all the pointers on the C stack will
become invalid.

To overcome this, all primitives that trigger gc_alloc() should be
purely functional, such that an allocation can restart the interpreter
step() that triggered the gc_alloc().

So.. If the gc itself is also made stateless (and written in CPS) then
this could work pretty well.

Lets see if gc_alloc() can be aborted.

Looks like it.. One problem however is that the current implementation
of gc_grow() will never be reached, so the program will end up in an
infinite loop when there isn't enough memory to account for a single
primitive execution.  Here the mark_wild() function would come in
handy:

If it is detected that a single primitive step cannot continue because
there is not enough heap space, the heap needs to grow.  As long as
gc_collect() doesn't abort the current GC invocation, this can be done
automatically.


Entry: constant strings
Date: Wed Aug  5 21:29:40 CEST 2009

Since these are not aligned, they cannot be objects.  So, no
constant strings.

Some goes for primitives.


Entry: First interpreter run
Date: Thu Aug  6 02:15:41 CEST 2009

# (zero? 123)

tom@zni:~/libprim/ceks$ ./gc-test
#state(#closure((zero? 123) ()) ())
#state(#closure(zero? ()) #frame(() (#closure(123 ())) ()))
#state(#closure(#prim<0x4014f3:1> ()) #frame(() (#closure(123 ())) ()))
#state(#closure(123 ()) #frame((#closure(#prim<0x4014f3:1> ())) () ()))
#state(#closure(#f ()) ())
ERROR: halt: #state(#closure(#f ()) ())
Trace/breakpoint trap



So primitive execution seems to work.  Still to test: abstraction and
application.  After fixing some bugs we're at:

# ((lambda (abc) 123) 456)

tom@zni:~/libprim/ceks$ ./gc-test
#state(#closure(((lambda (abc) 123) 456) ()) ())
#state(#closure((lambda (abc) 123) ()) #frame(() (#closure(456 ())) ()))
#state(#closure(#lambda(#(abc) 123) ()) #frame(() (#closure(456 ())) ()))
#state(#closure(456 ()) #frame((#closure(#lambda(#(abc) 123) ())) () ()))
#state(#closure(123 ((abc . #closure(456 ())))) ())
ERROR: halt: #state(#closure(123 ((abc . #closure(456 ())))) ())
Trace/breakpoint trap


Entry: Pre-emption
Date: Thu Aug  6 10:46:21 CEST 2009

So, let's install the preemption based garbage collector + write the
first `functional C' primitive task for parsing s-expressions = a
token enumerator.


Entry: constants vs. closures
Date: Thu Aug  6 12:09:08 CEST 2009

Yesterday went well.  The basic infrastructure seems to work.  Now I
need to get the small errors in the representation right.

Currently I have constants tagged to an environment.  This won't hurt,
but doesn't make much sense.  Maybe change the rep a bit.

The environment contains closures (open_term + environment) or
constants.

OK: it's way simpler to make everything a closure, but tag contstants
with an empty environment.

So.. Something is not right.  This gives an error:

   (post (cons 111 ((lambda (abc) 123) 456)))

ERROR: undefined: abc

I currently lost oversight so let's re-connect with the textbook
rules.


Entry: CEK primitives
Date: Thu Aug  6 15:01:19 CEST 2009

Looks like I'm confusing two things:

    * primitive values + fully reduced closures  (lambda + env)

    * non-fully reduced closures (application/varref/value + env)

I'd like to make sure that primitives only see primitive values and
fully reduced closures.  Also, primitives should be able to return
closures (even not fully reduced).

Where is the inconsistency?

Looking at PLLC[1] Chapter 6, p 74 at the CEK reduction rule [cek5], it
seems that primitives get passed _only_ primitive values, not
closures.

How can I make this consistent with a primitive that can operate on
closures as values?

Hmm.. Let's provide better names for the data structure.

1. A continuation frame represents the current state of argument
   evaluation from reducable closures to irreducable closures.

2. A fully evaluated continuation frame can be _applied_ which means
   that a new (reducable) closure is created by extending the closure
   in the first position with variables.


From what I could test it seems that application works fine.  So I
guess I need to figure out how to understand the difference between:

      - a machine where _all_ values are closures, but primitives can
        only accept and return primitive values (which have their
        environment dropped before primitive evaluation)

      - a machine where values are either closures or primitive
        values, and primitive functions can operate on both.

So, either the interpreter's notion of "closure" is made abstract, or
it is changed to directly operate on both primitive values and
closures.

What I could do is the following: regard interpreter state and
environment + data structures as different worlds.

STATE: the current reducable closure and continuation contain closure
structs only, but all communucation with the environment (extension
and reference) and primtives will pack/unpack closures to variables.

Ok. Added closure_pack() and closure_unpack().

[1] http://www.cs.utah.edu/plt/publications/pllc.pdf
[2] md5://3ab517a1167f86ef52caf3bf1a4fdb0c


Entry: Lists vs. applications
Date: Thu Aug  6 16:44:38 CEST 2009

Currently the implementation doesn't distinguish between applications
and lists.  The CEK machine doesn't deal with `constructors' which are
essentially non-evaluated functions.

I don't really know how this is done in practice.  Let's just wrap
code in a syntax object for now.

This seems to work.  There are now two kinds of terms: non-reduced
terms are SYNTAX while reduced terms are anything else.

Anyways.. It works, but it's probably a bit unorthodox.  This can't
represent syntax as values.  The real solution would be to represent
special forms, applications, variables references and quotes as
separate entities.

This will have to do for now.


Entry: Testing gc preemption
Date: Thu Aug  6 17:47:06 CEST 2009

Seems to work.  There is a problem though: triggering GC outside of
the mainloop is not well-defined.

This basicly boils down to the fact that the GC managed memory is
owned by the interpreter.  The caller of _sc_run() has no business
using these data structures.

It's useful for testing though.  It's necessary to perform a GC before
doing any allocation to prevent corruption.



Entry: Working?
Date: Thu Aug  6 18:51:02 CEST 2009

Looks like it's working. 

tom@zni:~/libprim/scheme$ wc -l *.[ch]
  167 gc.c
   10 gc_config.h
  133 gc.h
   54 main.c
  559 scheme.c
  201 scheme.h
   38 scheme_prim.h
   41 symbol.c
   28 symbol.h
 1231 total

It has almost nothing though.  Only evaluation + supporting prims.
Missing:
        - special forms (if, set!)
        - macros
        - reader
        - ports

The special forms might be enough so reader can maybe be written in
Scheme and compiled to C spec of the syntax tree?

Both special forms need modification to the continuation.  Assignment
will need to be done in such a way that GC interrupt isn't possible.

I'm adding a couple of structs to accomodate these different
continuation types.

Once realizing the frame type is only one of different kinds of
continuations, it was quite straigtforward to add 'if', 'set!',
'begin' and 'lambda' with multiple expressions.


Entry: Coroutines
Date: Thu Aug  6 19:30:26 CEST 2009

This paper defends the revival of (asymmetric) coroutines as a general
control abstraction[1].

[1] http://lambda-the-ultimate.org/node/2868


Entry: Macros
Date: Fri Aug  7 09:17:45 CEST 2009

This will require a syntax-level environment, and a lookup for every
form.

A macro continuation is simply a tag: the current value (s-expression)
needs to be tagged such that it is wrapped as SYNTAX and passed to the
interpreter.

I'm going to change the wording.  What is now SYNTAX should become
AST: a tag for reducable term.  SYNTAX in Scheme sense seems to be
something different: it is a data structure with binding information.
Even if I'm not going to support the latter, it's best not to confuse
things.

Ok, macros work by:  constructing a k_apply linked to k_macro.  The
k_apply is filled so it will trigger the application of the macro.
The k_macro wraps the result as an AST to trigger reduction.

Entry: C-Scheme
Date: Fri Aug  7 10:23:06 CEST 2009

Working with C-callable Scheme primitives makes the step towards a
PreScheme-like implementation easier.  Using only `let*', `if',
`begin', `set!', and a restriction on function application (only
primitives can be called from primitives) this could be turned into a
simple Scheme->C compiler.

At least, the way the interpreter step is implemented now in C +
Scheme datatypes, could be embedded into equivalent Scheme quite
easily.

        Scheme          C
        --------------------------------------------
        let*            Lexical variables and blocks.
        begin           Blocks.
        if              if statement.
        set!            Variable assignment.
        (fn arg ...)    Function call.
        prim-fn         C-implemented prim (or compiled from C-Scheme)
        
The only thing that won't work is `lambda'.  But, in case it is used
to pass to higher order functions (HOF), the HOF could be replaced
with a macro.

Note that PreScheme[1] is much more than this: it compiles a
significantly larger subset of Scheme.

Use pattern matching.


[1] http://en.wikipedia.org/wiki/PreScheme
[2] http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.3.4031


Entry: Really done?
Date: Fri Aug  7 11:38:25 CEST 2009

It looks like I have all of Scheme now.  Next: make some C-code
analysis tools that generate all the boilerplate.

One more thing is missing: variable length argument lists.  This is
necessary to implement `list' without which macros are no fun.


Entry: Two Kinds of Primitives
Date: Fri Aug  7 13:20:51 CEST 2009

Due to restart at GC, the interpreter can support two kinds of
primitives:

     * RESTARTABLE: Pure functions operating on Scheme data structures
       (or impure functions that do not perform allocation _after_
       mutation).

     * ABSTRACT: C code that does not refer to any Scheme data.

The disadvantage of not being able to access Scheme data from impure C
code can be largely removed by providing a suspension mechanism for
primitives.  In this case the C code could behave as a coroutine,
which allows the use of enumerators / iterators instead of
construction of intermediate data.

Impure functions performing allocation before mutation are hard to
write, and are best limited to the implementation of internal
primitives supporting mutation (like `set!' and `define') and adaptor
code that bridge Scheme and C datastructures for abstract functions.

In short: use either purely functional programming or concurrency
oriented programming, and you get a very simple interpreter and
application structure.


Entry: Bootstrapping
Date: Fri Aug  7 19:14:57 CEST 2009

Bootstrapping is fun.  It's the first time I did this for a Scheme
interpreter.  I've added two mzscheme .ss files.  One to convert .scm
files to .c_ files as long as there is no reader, and one to lift the
primitives from the .c file and write boilerplate registration code.

Then bootstrapping the rest of the basic scheme functionality on top
of the bare words is quite interesting.

One thing though: I don't immediately see how to make apply and eval
work.  Eval is probably iterating the step() function.  But apply?
Similarly maybe?  Constructing a continuation frame and iterating the
interpreter?

There is probably a simpler though non-obvious way to do this..
Manipulating the machine state from inside a primitive would probably
do the trick.

The trick is that the function modifies the continuation.  This could
be done using mutation, but that won't play nice with running the
interpreter manually (as part of debugging for instance).  It's
probably best to make it possible for primitives to return a
continuation.  Or better: to allow for explicit "state transforming"
primitives.

Let's thinkg about this first..

Before the step() function can really be a pure function, it has to
isolate all side effects, and should not rely on a main loop's
actions.

Maybe it's best to first try to implement call/cc.

Applying a continuation is really simple.  But how to capture it?
Looks like that's similar to apply.

Then about errors.  Maybe it is better to keep errors local to the
step() function that generated them, and return them as values
containing the continuation.  Except for GC restarts: they need to go
all the way up to make sure data is not corrupted.

Ok. errors are now local to step() allowing for recursive step() but
GC restart goes all the way up the chain.

Then a surprise: eval is (make-ast '(post 'foo-foo))

If a primitive returns a reducable term (represented by the ast
wrapper type), it will be evaluated.

Maybe apply can be made in a similar way?  Well.. I found something
that uses eval and map and quote.  Not pretty..

Looks like manipulating the continuation is best.


Entry: letcc -> apply
Date: Sat Aug  8 10:22:47 CEST 2009

It seems better to stick with the way things work right now, and use
only a single type of primitive.  This makes integration with C (the
eventual goal) a lot easier, and will prevent a lot of if-type style
code.

With `letcc' implemented as a special form, it is now possible to
create primitives that operate on continuations as data, creating new
continuations.  These values can themselves be applied.  This means
`apply' can be implemented as a continuation modification followed by
an application.

Yes, but.  The current k_apply type is a bit awkward, because it
evaluates from left to right, it will wait for the final argument
before coninuing with application.  Maybe it's simplest to support a
right-to-left app frame?

Before continuing, let's make the continuations somewhat abstract:
each with a parent slot in the first position.

Ok.

One way is to have a reverse k_apply: one that traverses the arguments
from right to left.  This way the `apply' continuation can be
constructed as an argument list, with the function value passed to it.
This would either require an extra reverse, or some re-arrangement in
the primitive call trampoline.

Or, a different kind of continuation could be made that ignores its
value, but passes closure to its parent continuation.

Basicly, such a continuation takes a value, ignores it, and passes
another value to its parent continuation.

Actually, this already exists: k_seq.

Indeed:  Using a continuation like this:
         
         _ -> (fn a1 a2 (begin _ a3))

will also ignore the supplied value and reduce to (fn a1 a2 a3).

    
Entry: closures and values
Date: Sat Aug  8 12:33:11 CEST 2009

So.. It's probably best to move closure_pack to the start of step(),
and unpack before adding to the environment.  It's a bit awkward the
way it is now.

Let's make it such that:

      - on step() entry, the closure is unpacked to perform reduction.

      - if there is no reduction, the value is packed.



Entry: magic values
Date: Sat Aug  8 12:47:55 CEST 2009

Because closures and ast's have a special meaning in the interpreter,
they cannot be used as values in Scheme.



Entry: Interesting
Date: Sat Aug  8 15:28:07 CEST 2009

Implementing this Scheme interpreter without relying on cons or
closures has been most revealing.  I never knew I knew so little about
the mechanics.  Arrogance tends to get in the way of learning..

There are some meta-confusion things in the syntax representation that
are a bit fishy still:

  - Syntax is wrapped in a weird way (tagged s-expressions.  a full
    parse into an AST so values and terms can never be confused would
    probably be better).

  - Because of this confusion, primitives can return reducable
    expressions (make-ast) and closures (make-closure) that will not
    behave as literal data.

As I've mentioned before, this makes make-ast behave as eval.

Maybe the solution is to explicitly represent non-reducable values as
VALUE?

Ok: 

 * all primitive return values will be tagged with VALUE
 * REDEX that is not a varref or an application is tagged as VALUE


Ok, I see..

It's probably best to get rid of the word "closure", and have two
kinds of values that contain environments:

      - redex
      - lambda

The trouble is primitive values.  In the lambda calculus, there are
only two kinds of terms: applications and abstractions, where
abstractions are values.

So.. Can I get rid of it in one try?  The code should be a lot clearer
with this..

I think I got the concept right, but there is some stray assignment
that messes up the GC.  Maybe time to isolate all assignments?

Inspecting the run state it gives something like:

... (#k_apply(#k_macro(#k_apply(#k_macro(#k_apply( ...

Ok.. recursive macro application.

After some more small tagging bugs (sc_apply_ktx required some head
scratching) it seems to work now.  The only remaining problem is the
invokation of (gc) from within scheme.

Was a problem with sc->entries.  Added sc->step_entries, which is a
different semaphore.

Seems to work now.  I can call the interpreter step from within scheme
+ all the state objects are available:

(make-value 123)
=> #value(123)

(eval-step (make-state (make-redex 'a '((a . 123))) (mt)))
=> #state(#value(123) #k_mt)

(eval-step (eval-step (make-state (make-redex 'a '((a . 123))) (mt))))
=> #error(halt 123 #state(#value(123) #k_mt))


Entry: Loop without cons
Date: Sun Aug  9 01:09:22 CEST 2009

So..  What would be necessary to make an interpreter that can perform
a loop without performing allocation?  It would need to overwrite
variables.

So..  What is scheme without GC?  This should be split in two: Scheme
with closures, but without continuations (using a stack) vs. Scheme
without closures, or only downward closures.


Entry: Reader task
Date: Sun Aug  9 11:32:40 CEST 2009

I got distracted..  Getting a front row view of how Scheme is
implemented on top of a bare machine is fascinating.

Anyways.  Now that the core of the interpreter seems to work, let's
make the first attempt at re-usable code: a reader = tokenizer +
"compressed ast parser" for s-expressions.

A compressed ast is a binary flat representation of a tree, consisting
of a stream of words.  This is important, because it will be the main
interface between two communicating processes that do not share
memory (or not all memory: they might share constant pointers.).



Entry: Keeping track of value names
Date: Sun Aug  9 12:05:38 CEST 2009

How to tag values with names?  Every time a value is lifted from the
environment, it could be recorded in the VALUE struct for debugging
purposes.  When there is an error, the current value's name could be
used for reporting.

Hmm..  It's not so simple..  It's probably easier to tag the primitive
struct itself with names.

Ok: solution was this: tag the sc struct with the primitive before
executing it: exceptions come from the call chain, or the interpreter.


Entry: Byte code
Date: Sun Aug  9 13:40:28 CEST 2009

More procrastination.  What would Scheme byte code look like?  It is
essentially creating a cached representation of the interpreter
sequencing.

The answer seems to be CPS conversion.


Entry: More library code
Date: Sun Aug  9 18:05:10 CEST 2009

let, letrec, named-let, apply, eval, cond.


Entry: Scheme interpreter next:
Date: Mon Aug 10 09:35:13 CEST 2009

critical path:

* C tasks -> reader (also find a standard protocol for transferring
  tree data using a machine word port interface).


structured procrastination:

* compilation to bytecode (CPS)

* subset compilation to C: i.e. embedding C in s-expr syntax using
  let* for set! begin while.  maybe augmented with a bit of
  optimizations to make the subset larger (PreScheme style).

* garbage collector: the stop & copy collector is good for
  bootstrapping, but it at least needs to be replaced by a cheney
  collector that doesn't use a stack.  maybe some more fancy things
  later.  this could be abstracted out and reused.



Entry: Tasks: one-shot + continuations
Date: Mon Aug 10 11:52:16 CEST 2009

It looks like the simplest approach is to use a `prompt'.  The current
tinyscheme implementation has a transparent mechanism: any C primitive
can be suspended relative to the setjmp right before primitive
execution.  The setjmp is also used for implementing exceptions.

The scheme in this project has a different structure: there is some
state unpacking between the mark and the actual primitive call.

This makes me thing it might be better to implement c continuations
and one-shot tasks using a primitive that marks the context.

OK. Continuations are working: they create a new ck struct on each
suspend.  It's probably to make one-shot continuations if the context
is reused + a context size check is performed.

NEXT: 
  - allocate before running (run on separate stack)
  - one-shot


Entry: GC
Date: Mon Aug 10 15:48:22 CEST 2009

Apparently there's a problem with finalization of atoms: if the
unreachable garbage space contains more than one reference to an atom,
its finalization will be called twice.

Hmm..

It looks like atoms that have a free() method need to be wrapped in a
vector, to make sure they only appear once in the heap.

So, the data needs a different encoding.

Let's start from what we need in the GC:

- vectors
- constants
- integers
- finalizers

An object that needs finalization which is not idempotent needs to be
wrapped in a vector.

OK: solved by removing the 'atom' type, but requiring that every
finalizer found in the heap is followed a pointer to finalize.  This
gives a simple mechanism to build wrapper vectors around arbitrary
(aligned) pointers: the client just needs to ensure that each object
occurs only in a single vector, and use that vector as the opaque
representation of the object.


Entry: Alloc before call
Date: Mon Aug 10 17:03:12 CEST 2009

Instead of allocating before calling a primitive, in the case where
the intermediate operation doesn't alloc, it might be simpler to see
if there is enough space and then postpone the allocation, in order
not to create garbage.


Entry: 0xbad
Date: Mon Aug 10 19:31:34 CEST 2009

A coincidence: usually this indicates problems :)

1: test_ck()
(123 . #aref(#fin<0xba6270:0x40123c> #data<0xbad420>))
2: test_ck()
(124 . #aref(#fin<0xba6270:0x40123c> #data<0xbad5b0>))
2: test_ck()
(124 . #aref(#fin<0xba6270:0x40123c> #data<0xbad740>))
2: test_ck()
(124 . #aref(#fin<0xba6270:0x40123c> #data<0xbad8d0>))
3: test_ck()
125


Entry: Dybvig Danfest 2004
Date: Mon Aug 10 23:19:58 CEST 2009

"The macro writers bill of rights"[1].

Check out KFFD hygienic expansion algo[4].  This lead me to hygienic
macros on top of unhygienic ones[2].

Apparently my letrec is wrong: all evaluations need to happen before
all assignments.

Optimizations: constant folding, copy propagation, inlining, dead code
elimnation.  Inlining (deciding to inline) isn't as easy as copy
propagation: you want your compiler to terminate and prevent code
explosion.

[1] http://video.google.com/videoplay?docid=-6899972066795135270
[2] http://p-cos.net/documents/hygiene.pdf
[3] http://people.csail.mit.edu/jaffer/r4rs_12.html
[4] http://www.cs.ucdavis.edu/~devanbu/teaching/260/kohlbecker.pdf

Entry: Sequential code
Date: Tue Aug 11 09:39:04 CEST 2009

Visually I associate left-aligned code in Scheme with side-effects
(begin).  However, parallel code also looks like this, and is not
necessarily bad from a mutation pov.


Entry: GCC
Date: Tue Aug 11 10:19:25 CEST 2009

Looking at the assembly output of scheme.c and it seems that it
performs the inlining well, except for the allocation, which uses a
vararg function _sc_make_struct that looks rather expensive to call.

Also, gc_alloc won't line.  I guess the `full' check prevents that.
It's probably easier to implement GC boundaries with unmapped pages.


Entry: bootstrap in forth
Date: Tue Aug 11 10:44:02 CEST 2009

Now, in order to get to a smaller code size.  What about writing the
step function in threaded code?  Does this make at all sense?

I don't think so: the features that are used to write the interpreter
are GC's vector construct (library) and C lexical scope and C
structure member scope.  It's rather awkward to write something like
that in a combinator language.


Entry: size
Date: Tue Aug 11 11:21:40 CEST 2009

Looks like the real culprit is the primitive registration code.  This
can be done in a table.

strip scheme
ls -l scheme

# currently
-rwxr-xr-x 1 tom tom 44592 2009-08-11 11:28 scheme

# Ha!
# The prim table actually made it bigger :)
-rwxr-xr-x 1 tom tom 45912 2009-08-11 11:34 scheme

# Changing the prototype of the function to take strings instead of
# symbols made it smaller:
-rwxr-xr-x 1 tom tom 43936 2009-08-11 12:02 scheme

So it's really the code that generates the boot code that bloats the
binary.  Looks like a reader is what's needed to compress further.

Also, part of the data structures could be loaded as constants:
symbols and primitives are not GC-managed, so they could be defined as
constant data.

Another thing that leads to bloat is the tag shifting.  Can this be
simplified to a single AND + compare?

After separating the bootstrap code to lib.o i get these stripped sizes:

# gcc -m32
-rw-r--r-- 1 tom tom  1256 2009-08-11 12:48 gc.o
-rw-r--r-- 1 tom tom 16116 2009-08-11 12:48 lib.o
-rw-r--r-- 1 tom tom  2032 2009-08-11 12:48 main.o
-rw-r--r-- 1 tom tom 12456 2009-08-11 12:48 scheme.o
-rw-r--r-- 1 tom tom   676 2009-08-11 12:48 symbol.o
-rw-r--r-- 1 tom tom  1136 2009-08-11 12:48 task.o

# gcc -m64
-rw-r--r-- 1 tom tom  1904 2009-08-11 12:49 gc.o
-rw-r--r-- 1 tom tom 18040 2009-08-11 12:49 lib.o
-rw-r--r-- 1 tom tom  2640 2009-08-11 12:49 main.o
-rw-r--r-- 1 tom tom 17344 2009-08-11 12:49 scheme.o
-rw-r--r-- 1 tom tom  1176 2009-08-11 12:49 symbol.o
-rw-r--r-- 1 tom tom  1832 2009-08-11 12:49 task.o


Entry: Compressing an s-expression into a serial protocol.
Date: Tue Aug 11 12:53:48 CEST 2009

What about this: create a small stack based VM spec that can can
create a data structure from an atom stack, and send the instructions
over the wire.

Hmm.. confusing..  Really I want a proper one-shot abstraction without
copying before attempting this.

What I really want is expanded AST compression or compilation to CPS
bytecode.


Entry: CPS conversion
Date: Tue Aug 11 13:57:19 CEST 2009

(lambda (x y) (fn (- x 1) (+ y 2)))

(lambda (x y k)
  a1 <- (- x 1)
  a2 <- (+ y 2)
  (fn a1 a2 k))


Entry: Local macros
Date: Tue Aug 11 14:06:20 CEST 2009

Let's support those by also recording the macro environment.  Looks
like it's easier to first support `let' as a special form, and then
reuse that code for `letmacro'.

`let' would use an application frame, where the first value is already
filled in (a lambda created from the body).  The same could be done
with `letmacro'.

What would be a `lambda' where the names are bound to macros instead
of values?  Maybe that's the simpler route?

Time to take a break, this is confusing..


Entry: Compiling to C and pattern matching
Date: Tue Aug 11 16:48:29 CEST 2009

Take the interpreter's main loop and write it as a pattern match in
Scheme syntax.  Actually: a pattern matcher is a language for writing
interpreters.

Basicly, all the C structs, predicates, and if/then/else blocks can be
automated easily, as long as it maps data -> data.  Otoh, the C code
itself isn't so difficult.



Entry: Dynamic languages workshop
Date: Tue Aug 11 17:05:08 CEST 2009

http://www.ai.mit.edu/projects/dynlangs/wizards-panels.html

David Moon:

 ``Start with a small working system and expand it incrementally,
   adding functionality and adding performance.  The big bang way only
   works for God.  Everyone else has to use evolution.''

 ``Sometimes an error message means exactly what it says.''


Entry: removing optimizations
Date: Tue Aug 11 17:45:36 CEST 2009

Heeding good advice: removing all optimizations that make code look
more complicated.


Entry: Real-time Garbage Collection
Date: Tue Aug 11 22:20:29 CEST 2009

Supercollider uses [1] while libgarbagecollector[2] is used in Io.
This one[3] is a rework of Metronome.

I'd like to know how this works..


[1] http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.4550
[2] http://www.dekorte.com/projects/opensource/libgarbagecollector/
[3] http://lambda-the-ultimate.org/node/2393

Entry: GC stuff
Date: Tue Aug 11 22:49:43 CEST 2009

Generational collection.

One of the key points seems to be that one mostly collects the
`nursery', a pool of recently allocated objects.  The assumption is
that most of the elements in the nursery will become garbage soon
after allocation (child mortality) AND that there are a lot of objects
that don't.  In order for this to work there needs to be a cheap way
of finding pointers that point from the heap at large into the (much
smaller) nursery.


Finalization: Instead of scanning the from space after copying, it's
also possible to perform the finalization later, when allocating anew:
the data will be moved to the cache anyway because of initialization,
so we might just as well access it then.



Entry: Cheyney GC
Date: Wed Aug 12 10:13:23 CEST 2009

Like a recursive mark and copy collector, but using a breadth-first
search.

  1 Copy all root objects: copy atoms, update moved vectors and copy
    vectors not yet moved.

  2 Copy all references in newly allocated objects.

  3 Repeat until heap stops growing (all reachable objects are moved).

OK: typed in, compiling, not working: it blows up.  Simplified, but I
can't see it.  Guess it's time for a proof.

An interesting challenge this is: I've always stayed away from
implementing graph algorithms in C.  It requires a lot of discipline
to get the invariants right.  The cause is usually due to embedding
and premature optimization, i.e. using the same field to represent two
distinct values in different modes when there are subtle cases where
this is not valid.  The Cheney algo is a simple one, but I couldn't
get it right ``just writing it down''.

Ha.. Indeed: caused by leaky abstractions: the problem was that vector
tags didn't get copied, which probably triggered an allocation loop in
the interpreter due to type errors.

Next: add assertions and error handling for the whole project.

[1] http://en.wikipedia.org/wiki/Cheney%27s_algorithm

